* [Why does deep and cheap learning work so well?](https://arxiv.org/pdf/1608.08225.pdf)
* [The Extraordinary Link Between Deep Neural Networks and the Nature of the Universe](https://www.technologyreview.com/s/602344/the-extraordinary-link-between-deep-neural-networks-and-the-nature-of-the-universe/)

## Unsupervised
* [Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders](https://arxiv.org/pdf/1611.02648.pdf)
* [G-means](https://papers.nips.cc/paper/2526-learning-the-k-in-k-means.pdf)

## Transfer learning
* [Transfer Learning of Latin and Greek Characters in Deep Neural Networks using Unsupervised Feature Learning](http://dylandrover.com/transfer_learning_RBM.pdf)

## Time series
* https://otexts.com/fpp2/missing-outliers.html
* https://stats.stackexchange.com/questions/287212/how-to-train-the-model-in-time-series-with-holiday-weekends

## Statistics
http://blog.shakirm.com/2015/10/machine-learning-trick-of-the-day-4-reparameterisation-tricks/

## Signal
* Transformata Hilberta

* [Shape Regression Machine](http://comaniciu.net/Papers/ShapeRegressionMachine_IPMI07.pdf)
* [DAWN Stanford](http://dawn.cs.stanford.edu/2017/07/05/yellowfin/)

* [Shape Analysis of Elastic Curves in Euclidean Spaces](https://pdfs.semanticscholar.org/5642/5f83e820b7711dd250fc7cc71c8e1bc177b4.pdf)

## Kernel methods
* [SVM](https://neuralnetset.blogspot.com/2018/01/what-are-kernels-in-machine-learning.html)

## RNN
http://blog.echen.me/2017/05/30/exploring-lstms/ 

* [Kinetic energy](https://alexandrudaia.quora.com/Kinetic-things-by-Daia-Alexandru)

## Gaussian Processes

* [Gaussian process with time series (Cross Validated)](https://stats.stackexchange.com/questions/320953/gaussian-process-with-time-series)
* [The Kernel Cookbook: Advice on Covariance functions](http://www.cs.toronto.edu/~duvenaud/cookbook/)
* [Bayesian machine learning.](https://github.com/jkfitzsimons/IPyNotebook_MachineLearning)
